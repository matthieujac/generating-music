{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df9dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for understanding music\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97701965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b5812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/beethoven_opus10_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2008 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/beethoven_opus10_2.mid\n",
      "Loading Music File: Beethoven/beethoven_opus10_3.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/beethoven_opus22_2.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_3.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_4.mid\n",
      "Loading Music File: Beethoven/pathetique_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 1. Movement'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/pathetique_2.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 2. Movement'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=7, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/pathetique_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 3. Movement'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_24772\\1273035479.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='Beethoven/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7209291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3715aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([167.,  31.,  16.,   7.,   4.,   2.,   5.,   3.,   4.,   3.]),\n",
       " array([  1. ,  77.2, 153.4, 229.6, 305.8, 382. , 458.2, 534.4, 610.6,\n",
       "        686.8, 763. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 328
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ffce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "338432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in notes_array:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae28d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68ff95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc1adddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f154f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24a98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257f5576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           24200     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 242)               62194     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 294,714\n",
      "Trainable params: 294,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24fbf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b82ace3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 4.5744\n",
      "Epoch 00001: val_loss improved from inf to 4.50043, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 4.5741 - val_loss: 4.5004\n",
      "Epoch 2/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 4.2170\n",
      "Epoch 00002: val_loss improved from 4.50043 to 4.15591, saving model to best_model.h5\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 4.2171 - val_loss: 4.1559\n",
      "Epoch 3/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.9326\n",
      "Epoch 00003: val_loss improved from 4.15591 to 3.97696, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 3.9322 - val_loss: 3.9770\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 3.7513\n",
      "Epoch 00004: val_loss improved from 3.97696 to 3.90960, saving model to best_model.h5\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 3.7513 - val_loss: 3.9096\n",
      "Epoch 5/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.6282\n",
      "Epoch 00005: val_loss improved from 3.90960 to 3.82207, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 60ms/step - loss: 3.6284 - val_loss: 3.8221\n",
      "Epoch 6/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.5261\n",
      "Epoch 00006: val_loss improved from 3.82207 to 3.74093, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 3.5263 - val_loss: 3.7409\n",
      "Epoch 7/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.4289\n",
      "Epoch 00007: val_loss improved from 3.74093 to 3.68150, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 3.4287 - val_loss: 3.6815\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 3.3479\n",
      "Epoch 00008: val_loss improved from 3.68150 to 3.63831, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 3.3479 - val_loss: 3.6383\n",
      "Epoch 9/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.2799\n",
      "Epoch 00009: val_loss improved from 3.63831 to 3.56015, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 3.2794 - val_loss: 3.5601\n",
      "Epoch 10/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.2074\n",
      "Epoch 00010: val_loss did not improve from 3.56015\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 3.2075 - val_loss: 3.5626\n",
      "Epoch 11/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.1443\n",
      "Epoch 00011: val_loss improved from 3.56015 to 3.49226, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 3.1444 - val_loss: 3.4923\n",
      "Epoch 12/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.0912\n",
      "Epoch 00012: val_loss improved from 3.49226 to 3.44906, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 3.0910 - val_loss: 3.4491\n",
      "Epoch 13/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3.0318\n",
      "Epoch 00013: val_loss improved from 3.44906 to 3.43592, saving model to best_model.h5\n",
      "140/140 [==============================] - 9s 64ms/step - loss: 3.0315 - val_loss: 3.4359\n",
      "Epoch 14/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.9869\n",
      "Epoch 00014: val_loss improved from 3.43592 to 3.41546, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 2.9865 - val_loss: 3.4155\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.9357\n",
      "Epoch 00015: val_loss improved from 3.41546 to 3.34946, saving model to best_model.h5\n",
      "140/140 [==============================] - 9s 61ms/step - loss: 2.9357 - val_loss: 3.3495\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.8871\n",
      "Epoch 00016: val_loss improved from 3.34946 to 3.33613, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 2.8871 - val_loss: 3.3361\n",
      "Epoch 17/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 2.8450\n",
      "Epoch 00017: val_loss improved from 3.33613 to 3.32828, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 2.8454 - val_loss: 3.3283\n",
      "Epoch 18/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.8014\n",
      "Epoch 00018: val_loss improved from 3.32828 to 3.30106, saving model to best_model.h5\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 2.8012 - val_loss: 3.3011\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.7662\n",
      "Epoch 00019: val_loss did not improve from 3.30106\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 2.7662 - val_loss: 3.3064\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.7123\n",
      "Epoch 00020: val_loss improved from 3.30106 to 3.28020, saving model to best_model.h5\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 2.7123 - val_loss: 3.2802\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.6814\n",
      "Epoch 00021: val_loss improved from 3.28020 to 3.27385, saving model to best_model.h5\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 2.6814 - val_loss: 3.2739\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.6471\n",
      "Epoch 00022: val_loss did not improve from 3.27385\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 2.6471 - val_loss: 3.2744\n",
      "Epoch 23/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.6145\n",
      "Epoch 00023: val_loss improved from 3.27385 to 3.24138, saving model to best_model.h5\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 2.6149 - val_loss: 3.2414\n",
      "Epoch 24/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.5793\n",
      "Epoch 00024: val_loss improved from 3.24138 to 3.23928, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 2.5787 - val_loss: 3.2393\n",
      "Epoch 25/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.5554\n",
      "Epoch 00025: val_loss improved from 3.23928 to 3.21215, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 2.5550 - val_loss: 3.2122\n",
      "Epoch 26/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.5202\n",
      "Epoch 00026: val_loss improved from 3.21215 to 3.20830, saving model to best_model.h5\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 2.5209 - val_loss: 3.2083\n",
      "Epoch 27/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.4923\n",
      "Epoch 00027: val_loss improved from 3.20830 to 3.19061, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 2.4920 - val_loss: 3.1906\n",
      "Epoch 28/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 2.4639\n",
      "Epoch 00028: val_loss did not improve from 3.19061\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 2.4626 - val_loss: 3.1937\n",
      "Epoch 29/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.4312\n",
      "Epoch 00029: val_loss improved from 3.19061 to 3.17342, saving model to best_model.h5\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 2.4305 - val_loss: 3.1734\n",
      "Epoch 30/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.4147\n",
      "Epoch 00030: val_loss did not improve from 3.17342\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 2.4147 - val_loss: 3.1814\n",
      "Epoch 31/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.3895\n",
      "Epoch 00031: val_loss did not improve from 3.17342\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 2.3896 - val_loss: 3.2023\n",
      "Epoch 32/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 2.3670\n",
      "Epoch 00032: val_loss improved from 3.17342 to 3.17335, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 39ms/step - loss: 2.3684 - val_loss: 3.1734\n",
      "Epoch 33/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.3360\n",
      "Epoch 00033: val_loss did not improve from 3.17335\n",
      "140/140 [==============================] - 5s 39ms/step - loss: 2.3354 - val_loss: 3.1911\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/140 [============================>.] - ETA: 0s - loss: 2.3094\n",
      "Epoch 00034: val_loss improved from 3.17335 to 3.16179, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 2.3101 - val_loss: 3.1618\n",
      "Epoch 35/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.2947\n",
      "Epoch 00035: val_loss improved from 3.16179 to 3.16068, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 2.2947 - val_loss: 3.1607\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.2753\n",
      "Epoch 00036: val_loss improved from 3.16068 to 3.15452, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 2.2753 - val_loss: 3.1545\n",
      "Epoch 37/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.2454\n",
      "Epoch 00037: val_loss improved from 3.15452 to 3.15096, saving model to best_model.h5\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 2.2460 - val_loss: 3.1510\n",
      "Epoch 38/50\n",
      "138/140 [============================>.] - ETA: 0s - loss: 2.2238\n",
      "Epoch 00038: val_loss improved from 3.15096 to 3.13447, saving model to best_model.h5\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 2.2272 - val_loss: 3.1345\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.2045\n",
      "Epoch 00039: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 2.2045 - val_loss: 3.1549\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.1793\n",
      "Epoch 00040: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 2.1793 - val_loss: 3.1412\n",
      "Epoch 41/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.1858\n",
      "Epoch 00041: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 2.1856 - val_loss: 3.1512\n",
      "Epoch 42/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.1499\n",
      "Epoch 00042: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 2.1503 - val_loss: 3.1535\n",
      "Epoch 43/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.1399\n",
      "Epoch 00043: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 2.1388 - val_loss: 3.1431\n",
      "Epoch 44/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.1241\n",
      "Epoch 00044: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 2.1249 - val_loss: 3.1487\n",
      "Epoch 45/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.1157\n",
      "Epoch 00045: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 9s 65ms/step - loss: 2.1159 - val_loss: 3.1516\n",
      "Epoch 46/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.0868\n",
      "Epoch 00046: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 2.0869 - val_loss: 3.1699\n",
      "Epoch 47/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.0736\n",
      "Epoch 00047: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 2.0738 - val_loss: 3.1512\n",
      "Epoch 48/50\n",
      "139/140 [============================>.] - ETA: 0s - loss: 2.0582\n",
      "Epoch 00048: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 2.0583 - val_loss: 3.1456\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.0362\n",
      "Epoch 00049: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 2.0362 - val_loss: 3.1686\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.0447\n",
      "Epoch 00050: val_loss did not improve from 3.13447\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 2.0447 - val_loss: 3.1610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b577243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "412df988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176, 16, 176, 16, 178, 16, 103, 16, 103, 16, 103, 16, 103, 157, 176, 5, 214, 103, 103, 176, 214, 178, 178, 178, 103, 214, 214, 103, 214, 214, 214, 214, 214, 186, 186, 134, 186, 134, 134, 134, 134, 187, 187, 134, 134, 134, 134, 134, 134, 134]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(50):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88712601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f1fb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e38af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e40ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
